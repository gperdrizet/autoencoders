{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow import keras\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Local imports\n",
    "from src.data_utils import CIFAR10_CLASSES, load_cifar10\n",
    "from src.model_utils import build_vae\n",
    "from src.visualization import (\n",
    "    plot_image_grid,\n",
    "    plot_interpolation,\n",
    "    plot_latent_space_2d\n",
    ")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'GPU Available: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b8baf",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10(normalize=True)\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "print(f\"Image shape: {x_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "sample_indices = np.random.choice(len(x_test), 10, replace=False)\n",
    "sample_images = x_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]\n",
    "titles = [CIFAR10_CLASSES[label] for label in sample_labels]\n",
    "\n",
    "fig = plot_image_grid(sample_images, titles=titles)\n",
    "plt.suptitle('Sample CIFAR-10 Images', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e2134",
   "metadata": {},
   "source": [
    "## Build Variational Autoencoder\n",
    "\n",
    "The VAE consists of:\n",
    "1. **Encoder**: Maps images to latent distribution (μ, σ²)\n",
    "2. **Sampling Layer**: Samples z using reparameterization trick\n",
    "3. **Decoder**: Maps latent samples back to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac76238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Configuration\n",
    "LATENT_DIM = 128\n",
    "EPOCHS = 100  # VAEs typically need more training\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Create directories\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logs_dir = Path('../logs')\n",
    "logs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VAE\n",
    "vae, encoder, decoder = build_vae(latent_dim=LATENT_DIM)\n",
    "\n",
    "# Compile\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "print(f\"\\nVAE Parameters: {vae.count_params():,}\")\n",
    "print(f\"Encoder Parameters: {encoder.count_params():,}\")\n",
    "print(f\"Decoder Parameters: {decoder.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12536d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architectures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENCODER ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "encoder.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DECODER ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0f664",
   "metadata": {},
   "source": [
    "## Train the VAE\n",
    "\n",
    "Training a VAE involves optimizing:\n",
    "- **Reconstruction Loss**: How well can we reconstruct the input?\n",
    "- **KL Divergence**: How close is the latent distribution to N(0,1)?\n",
    "\n",
    "Total Loss = Reconstruction Loss + β × KL Divergence\n",
    "\n",
    "We use β = 0.0005 for CIFAR-10 (beta-VAE) to balance the two terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192353e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(models_dir / 'vae.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=str(logs_dir / 'vae'),\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Variational Autoencoder\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "history = vae.fit(\n",
    "    x_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(x_test,),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model saved to: models/vae.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3c52b",
   "metadata": {},
   "source": [
    "## Visualize Training Progress\n",
    "\n",
    "VAE training involves monitoring multiple loss components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total loss\n",
    "axes[0].plot(history.history['loss'], label='Train')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].set_title('Total VAE Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[1].plot(history.history['reconstruction_loss'], label='Train')\n",
    "if 'val_reconstruction_loss' in history.history:\n",
    "    axes[1].plot(history.history['val_reconstruction_loss'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Reconstruction Loss')\n",
    "axes[1].set_title('Reconstruction Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# KL divergence\n",
    "axes[2].plot(history.history['kl_loss'], label='Train')\n",
    "if 'val_kl_loss' in history.history:\n",
    "    axes[2].plot(history.history['val_kl_loss'], label='Validation')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('KL Divergence')\n",
    "axes[2].set_title('KL Divergence Loss')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VAE Training History', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bba0d0",
   "metadata": {},
   "source": [
    "## Generate New Images\n",
    "\n",
    "Now the fun part! We can sample from the latent space to generate new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples\n",
    "n_samples = 20\n",
    "\n",
    "# Sample from standard normal distribution\n",
    "random_latent_vectors = np.random.normal(size=(n_samples, LATENT_DIM))\n",
    "\n",
    "# Decode to images\n",
    "generated_images = decoder.predict(random_latent_vectors, verbose=0)\n",
    "\n",
    "# Display\n",
    "fig = plot_image_grid(generated_images, rows=4, cols=5, figsize=(15, 12))\n",
    "plt.suptitle('Randomly Generated Images from VAE', fontsize=16, y=0.995)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33d82c",
   "metadata": {},
   "source": [
    "## Compare: Real vs Reconstructed vs Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test samples\n",
    "n_compare = 5\n",
    "test_samples = x_test[np.random.choice(len(x_test), n_compare, replace=False)]\n",
    "\n",
    "# Reconstruct\n",
    "reconstructed = vae.predict(test_samples, verbose=0)\n",
    "\n",
    "# Generate new\n",
    "random_z = np.random.normal(size=(n_compare, LATENT_DIM))\n",
    "generated = decoder.predict(random_z, verbose=0)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(3, n_compare, figsize=(n_compare * 3, 9))\n",
    "\n",
    "for i in range(n_compare):\n",
    "    # Real\n",
    "    axes[0, i].imshow(test_samples[i])\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Real Images', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Reconstructed\n",
    "    axes[1, i].imshow(reconstructed[i])\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Reconstructed', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Generated\n",
    "    axes[2, i].imshow(generated[i])\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_title('Generated (Random)', fontweight='bold', fontsize=14, color='green')\n",
    "\n",
    "plt.suptitle('Real vs Reconstructed vs Generated', fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13883fdc",
   "metadata": {},
   "source": [
    "## Latent Space Interpolation\n",
    "\n",
    "One of the coolest features of VAEs: smooth interpolation between images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7be846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two images to interpolate between\n",
    "idx1, idx2 = 42, 123\n",
    "img1 = x_test[idx1:idx1+1]\n",
    "img2 = x_test[idx2:idx2+1]\n",
    "\n",
    "# Encode to latent space (use mean, not sampled z)\n",
    "z1_mean, _, _ = encoder.predict(img1, verbose=0)\n",
    "z2_mean, _, _ = encoder.predict(img2, verbose=0)\n",
    "\n",
    "# Interpolate\n",
    "n_steps = 10\n",
    "interpolated_z = []\n",
    "for alpha in np.linspace(0, 1, n_steps):\n",
    "    z = (1 - alpha) * z1_mean + alpha * z2_mean\n",
    "    interpolated_z.append(z)\n",
    "\n",
    "interpolated_z = np.vstack(interpolated_z)\n",
    "\n",
    "# Decode\n",
    "interpolated_images = decoder.predict(interpolated_z, verbose=0)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, n_steps, figsize=(n_steps * 2, 2))\n",
    "\n",
    "for i in range(n_steps):\n",
    "    axes[i].imshow(interpolated_images[i])\n",
    "    axes[i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i].set_title('Start', fontweight='bold')\n",
    "    elif i == n_steps - 1:\n",
    "        axes[i].set_title('End', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Latent Space Interpolation', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9135506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple interpolations\n",
    "fig, axes = plt.subplots(5, n_steps, figsize=(n_steps * 2, 10))\n",
    "\n",
    "for row in range(5):\n",
    "    # Random pair\n",
    "    idx1, idx2 = np.random.choice(len(x_test), 2, replace=False)\n",
    "    img1 = x_test[idx1:idx1+1]\n",
    "    img2 = x_test[idx2:idx2+1]\n",
    "    \n",
    "    # Encode and interpolate\n",
    "    z1_mean, _, _ = encoder.predict(img1, verbose=0)\n",
    "    z2_mean, _, _ = encoder.predict(img2, verbose=0)\n",
    "    \n",
    "    interpolated_z = []\n",
    "    for alpha in np.linspace(0, 1, n_steps):\n",
    "        z = (1 - alpha) * z1_mean + alpha * z2_mean\n",
    "        interpolated_z.append(z)\n",
    "    \n",
    "    interpolated_z = np.vstack(interpolated_z)\n",
    "    interpolated_images = decoder.predict(interpolated_z, verbose=0)\n",
    "    \n",
    "    # Display\n",
    "    for i in range(n_steps):\n",
    "        axes[row, i].imshow(interpolated_images[i])\n",
    "        axes[row, i].axis('off')\n",
    "\n",
    "plt.suptitle('Multiple Latent Space Interpolations', fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a358f4",
   "metadata": {},
   "source": [
    "## Visualize Latent Space Structure\n",
    "\n",
    "Let's use t-SNE to visualize the 2D structure of our high-dimensional latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7533769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a subset of test data\n",
    "n_viz = 2000\n",
    "viz_indices = np.random.choice(len(x_test), n_viz, replace=False)\n",
    "viz_images = x_test[viz_indices]\n",
    "viz_labels = y_test[viz_indices]\n",
    "\n",
    "print(\"Encoding images to latent space...\")\n",
    "z_mean, z_log_var, z = encoder.predict(viz_images, verbose=1)\n",
    "\n",
    "print(\"\\nComputing t-SNE projection...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "z_2d = tsne.fit_transform(z_mean)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot latent space colored by class\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create a scatter plot for each class\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "for class_idx in range(10):\n",
    "    mask = viz_labels == class_idx\n",
    "    ax.scatter(\n",
    "        z_2d[mask, 0],\n",
    "        z_2d[mask, 1],\n",
    "        c=[colors[class_idx]],\n",
    "        label=CIFAR10_CLASSES[class_idx],\n",
    "        alpha=0.6,\n",
    "        s=20\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "ax.set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "ax.set_title('VAE Latent Space (t-SNE Projection)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c2bba",
   "metadata": {},
   "source": [
    "## Latent Space Arithmetic\n",
    "\n",
    "We can perform arithmetic in latent space: `z_cat + z_dog - z_bird = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc318a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find examples of specific classes\n",
    "def get_class_example(class_idx, dataset, labels):\n",
    "    \"\"\"Get a random example of a specific class.\"\"\"\n",
    "    class_indices = np.where(labels == class_idx)[0]\n",
    "    idx = np.random.choice(class_indices)\n",
    "    return dataset[idx:idx+1]\n",
    "\n",
    "# Get examples\n",
    "cat_img = get_class_example(3, x_test, y_test)  # cat\n",
    "dog_img = get_class_example(5, x_test, y_test)  # dog\n",
    "bird_img = get_class_example(2, x_test, y_test) # bird\n",
    "\n",
    "# Encode to latent space\n",
    "cat_z, _, _ = encoder.predict(cat_img, verbose=0)\n",
    "dog_z, _, _ = encoder.predict(dog_img, verbose=0)\n",
    "bird_z, _, _ = encoder.predict(bird_img, verbose=0)\n",
    "\n",
    "# Latent arithmetic\n",
    "result_z = cat_z + dog_z - bird_z\n",
    "\n",
    "# Decode\n",
    "result_img = decoder.predict(result_z, verbose=0)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 7, figsize=(14, 2))\n",
    "\n",
    "axes[0].imshow(cat_img[0])\n",
    "axes[0].set_title('Cat', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].text(0.5, 0.5, '+', fontsize=24, ha='center', va='center')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(dog_img[0])\n",
    "axes[2].set_title('Dog', fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].text(0.5, 0.5, '-', fontsize=24, ha='center', va='center')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].imshow(bird_img[0])\n",
    "axes[4].set_title('Bird', fontweight='bold')\n",
    "axes[4].axis('off')\n",
    "\n",
    "axes[5].text(0.5, 0.5, '=', fontsize=24, ha='center', va='center')\n",
    "axes[5].axis('off')\n",
    "\n",
    "axes[6].imshow(result_img[0])\n",
    "axes[6].set_title('Result', fontweight='bold', color='green')\n",
    "axes[6].axis('off')\n",
    "\n",
    "plt.suptitle('Latent Space Arithmetic', fontsize=14, y=1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc9f47",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Generative Capability**: VAEs can generate new, plausible images by sampling from the latent space.\n",
    "\n",
    "2. **Smooth Latent Space**: The probabilistic nature of VAEs creates a continuous latent space, enabling smooth interpolations.\n",
    "\n",
    "3. **Learned Structure**: The latent space organizes semantically similar images together, as shown by the t-SNE visualization.\n",
    "\n",
    "4. **Interpretable Representations**: Latent space arithmetic suggests meaningful feature representations.\n",
    "\n",
    "### Advantages of VAEs:\n",
    "\n",
    "- **Principled probabilistic framework**: Based on variational inference\n",
    "- **Continuous latent space**: Enables interpolation and exploration\n",
    "- **Balanced objectives**: Reconstruction + regularization via KL divergence\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "- Generated images can be blurry (compared to GANs)\n",
    "- Requires careful tuning of β (KL divergence weight)\n",
    "- More complex training than standard autoencoders\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Creative tools**: Generate variations of designs, artworks\n",
    "- **Data augmentation**: Create synthetic training data\n",
    "- **Compression**: Lossy compression with generative reconstruction\n",
    "- **Drug discovery**: Generate novel molecular structures\n",
    "- **Anomaly detection**: Probabilistic anomaly scores\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Explore the Streamlit app for interactive generation\n",
    "2. Try conditional VAEs (CVAEs) to control generation by class\n",
    "3. Experiment with different β values (β-VAE)\n",
    "4. Compare with GANs and diffusion models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
