{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d71b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Local imports\n",
    "from src.data_utils import CIFAR10_CLASSES, load_cifar10\n",
    "from src.metrics import compute_metrics_summary\n",
    "from src.model_utils import build_compression_ae\n",
    "from src.visualization import plot_image_grid, plot_reconstruction_comparison, plot_training_history\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'GPU Available: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494cc86",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10 Dataset\n",
    "\n",
    "CIFAR-10 consists of 60,000 32x32 color images in 10 classes. We'll use it to train our compression autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9eedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10(normalize=True)\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "print(f\"Image shape: {x_train.shape[1:]}\")\n",
    "print(f\"Classes: {CIFAR10_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "sample_indices = np.random.choice(len(x_test), 10, replace=False)\n",
    "sample_images = x_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]\n",
    "titles = [CIFAR10_CLASSES[label] for label in sample_labels]\n",
    "\n",
    "fig = plot_image_grid(sample_images, titles=titles)\n",
    "plt.suptitle('Sample CIFAR-10 Images', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c374fb9",
   "metadata": {},
   "source": [
    "## Train Compression Autoencoders\n",
    "\n",
    "We'll train separate models with different latent dimensions to explore the compression-quality trade-off:\n",
    "\n",
    "- **Latent dim 32**: Highest compression (~96% size reduction)\n",
    "- **Latent dim 64**: High compression (~94% size reduction)\n",
    "- **Latent dim 128**: Moderate compression (~88% size reduction)\n",
    "- **Latent dim 256**: Lower compression (~75% size reduction)\n",
    "\n",
    "Original image size: 32 × 32 × 3 = 3,072 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "LATENT_DIMS = [32, 64, 128, 256]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create logs directory for TensorBoard\n",
    "logs_dir = Path('../logs')\n",
    "logs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cdd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for each latent dimension\n",
    "trained_models = {}\n",
    "histories = {}\n",
    "\n",
    "for latent_dim in LATENT_DIMS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Autoencoder with Latent Dimension: {latent_dim}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Build model\n",
    "    autoencoder, encoder, decoder = build_compression_ae(latent_dim=latent_dim)\n",
    "    \n",
    "    # Compile\n",
    "    autoencoder.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel Summary:\")\n",
    "    print(f\"Total parameters: {autoencoder.count_params():,}\")\n",
    "    print(f\"Compression ratio: {3072/latent_dim:.2f}x\\n\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(models_dir / f'compression_ae_latent{latent_dim}.keras'),\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=str(logs_dir / f'compression_latent{latent_dim}'),\n",
    "            histogram_freq=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history = autoencoder.fit(\n",
    "        x_train, x_train,  # Input and target are the same\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_test, x_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    trained_models[latent_dim] = autoencoder\n",
    "    histories[latent_dim] = history\n",
    "    \n",
    "    print(f\"\\n✅ Model saved to: models/compression_ae_latent{latent_dim}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce55be",
   "metadata": {},
   "source": [
    "## Visualize Training History\n",
    "\n",
    "Let's examine how the models learned over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b203e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for all models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for latent_dim, history in histories.items():\n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label=f'Latent {latent_dim} (train)', alpha=0.7)\n",
    "    axes[0].plot(history.history['val_loss'], label=f'Latent {latent_dim} (val)', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "for latent_dim, history in histories.items():\n",
    "    axes[1].plot(history.history['mae'], label=f'Latent {latent_dim} (train)', alpha=0.7)\n",
    "    axes[1].plot(history.history['val_mae'], label=f'Latent {latent_dim} (val)', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Mean Absolute Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001868f",
   "metadata": {},
   "source": [
    "## Evaluate Reconstruction Quality\n",
    "\n",
    "Now let's evaluate the quality of reconstructions using various metrics:\n",
    "- **MSE** (Mean Squared Error): Lower is better\n",
    "- **PSNR** (Peak Signal-to-Noise Ratio): Higher is better (typically 20-40 dB)\n",
    "- **SSIM** (Structural Similarity Index): Higher is better (0-1 scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "evaluation_results = {}\n",
    "\n",
    "# Use a subset of test data for evaluation\n",
    "eval_samples = x_test[:1000]\n",
    "\n",
    "for latent_dim, model in trained_models.items():\n",
    "    print(f\"\\nEvaluating Latent Dim {latent_dim}...\")\n",
    "    \n",
    "    # Generate reconstructions\n",
    "    reconstructions = model.predict(eval_samples, verbose=0)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics_summary(eval_samples, reconstructions, latent_dim)\n",
    "    evaluation_results[latent_dim] = metrics\n",
    "    \n",
    "    print(f\"  MSE: {metrics['mse']:.6f}\")\n",
    "    print(f\"  PSNR: {metrics['psnr']:.2f} dB\")\n",
    "    print(f\"  SSIM: {metrics['ssim']:.4f}\")\n",
    "    print(f\"  Compression Ratio: {metrics['compression_ratio']:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e47611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(evaluation_results).T\n",
    "df.index.name = 'Latent Dim'\n",
    "df = df.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPRESSION VS QUALITY COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string())\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53644e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize compression-quality trade-off\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "latent_dims = list(evaluation_results.keys())\n",
    "compression_ratios = [evaluation_results[ld]['compression_ratio'] for ld in latent_dims]\n",
    "psnr_values = [evaluation_results[ld]['psnr'] for ld in latent_dims]\n",
    "ssim_values = [evaluation_results[ld]['ssim'] for ld in latent_dims]\n",
    "mse_values = [evaluation_results[ld]['mse'] for ld in latent_dims]\n",
    "\n",
    "# PSNR vs Compression\n",
    "axes[0].plot(compression_ratios, psnr_values, marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Compression Ratio')\n",
    "axes[0].set_ylabel('PSNR (dB)')\n",
    "axes[0].set_title('PSNR vs Compression Ratio')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].invert_xaxis()\n",
    "\n",
    "# SSIM vs Compression\n",
    "axes[1].plot(compression_ratios, ssim_values, marker='s', linewidth=2, markersize=8, color='green')\n",
    "axes[1].set_xlabel('Compression Ratio')\n",
    "axes[1].set_ylabel('SSIM')\n",
    "axes[1].set_title('SSIM vs Compression Ratio')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].invert_xaxis()\n",
    "\n",
    "# MSE vs Compression\n",
    "axes[2].plot(compression_ratios, mse_values, marker='^', linewidth=2, markersize=8, color='red')\n",
    "axes[2].set_xlabel('Compression Ratio')\n",
    "axes[2].set_ylabel('MSE')\n",
    "axes[2].set_title('MSE vs Compression Ratio')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].invert_xaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099cd0e5",
   "metadata": {},
   "source": [
    "## Visual Comparison of Reconstructions\n",
    "\n",
    "Let's visually compare the reconstruction quality across different latent dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random test images\n",
    "n_samples = 5\n",
    "sample_indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "test_samples = x_test[sample_indices]\n",
    "\n",
    "# Create comparison figure\n",
    "fig, axes = plt.subplots(len(LATENT_DIMS) + 1, n_samples, figsize=(n_samples * 3, (len(LATENT_DIMS) + 1) * 3))\n",
    "\n",
    "# Display originals\n",
    "for i in range(n_samples):\n",
    "    axes[0, i].imshow(test_samples[i])\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Original', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Display reconstructions for each latent dimension\n",
    "for row_idx, latent_dim in enumerate(LATENT_DIMS, start=1):\n",
    "    model = trained_models[latent_dim]\n",
    "    reconstructions = model.predict(test_samples, verbose=0)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[row_idx, i].imshow(reconstructions[i])\n",
    "        axes[row_idx, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[row_idx, i].set_title(f'Latent {latent_dim}\\n(Ratio: {3072/latent_dim:.1f}x)', \n",
    "                                       fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.suptitle('Reconstruction Quality Comparison', fontsize=18, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc926b",
   "metadata": {},
   "source": [
    "## Per-Class Performance Analysis\n",
    "\n",
    "Let's see how well the autoencoder performs on different object classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import calculate_psnr\n",
    "\n",
    "# Use the best model (latent_dim=128 is a good balance)\n",
    "best_model = trained_models[128]\n",
    "\n",
    "# Calculate PSNR for each class\n",
    "class_psnr = {}\n",
    "\n",
    "for class_idx, class_name in enumerate(CIFAR10_CLASSES):\n",
    "    # Get images of this class\n",
    "    class_mask = y_test == class_idx\n",
    "    class_images = x_test[class_mask][:100]  # Use first 100 samples\n",
    "    \n",
    "    # Reconstruct\n",
    "    reconstructions = best_model.predict(class_images, verbose=0)\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr = np.mean(calculate_psnr(class_images, reconstructions))\n",
    "    class_psnr[class_name] = psnr\n",
    "\n",
    "# Plot per-class performance\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "classes = list(class_psnr.keys())\n",
    "psnr_values = list(class_psnr.values())\n",
    "\n",
    "bars = ax.bar(classes, psnr_values, color='steelblue', alpha=0.8)\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "ax.set_title('Reconstruction Quality by Class (Latent Dim: 128)', fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=np.mean(psnr_values), color='red', linestyle='--', label=f'Mean: {np.mean(psnr_values):.2f} dB')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPer-Class PSNR:\")\n",
    "for class_name, psnr in class_psnr.items():\n",
    "    print(f\"  {class_name:12s}: {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c76e5d",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Compression-Quality Trade-off**: Higher compression ratios lead to lower reconstruction quality, as expected.\n",
    "\n",
    "2. **Optimal Balance**: Latent dimension of 128 provides a good balance between compression (~24x) and quality.\n",
    "\n",
    "3. **Class Variability**: Some classes (e.g., simpler objects) compress better than others.\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Image storage**: Reduce storage requirements with acceptable quality loss\n",
    "- **Bandwidth optimization**: Transmit compressed latent representations\n",
    "- **Feature extraction**: Use latent representations for downstream tasks\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Explore the trained models in the Streamlit app for interactive demos\n",
    "2. Try the anomaly detection notebook to see autoencoders in a different context\n",
    "3. Learn about VAEs for generative modeling in notebook 03"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
