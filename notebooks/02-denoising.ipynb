{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d68789a",
   "metadata": {},
   "source": [
    "# Denoising autoencoder\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0db006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Local imports\n",
    "from src.data_utils import load_coco_cached\n",
    "from src.visualization import plot_image_grid\n",
    "from src.noise import add_gaussian_noise, add_salt_pepper_noise, add_speckle_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95daa795",
   "metadata": {},
   "source": [
    "### 1.2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f59d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAIN_MODEL = True  # Set to False to download pre-trained model from HuggingFace\n",
    "\n",
    "# Training hyperparameters\n",
    "LATENT_DIM = 128\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Noise parameters\n",
    "NOISE_FACTOR = 0.25  # Train/evaluate strictly on Gaussian noise\n",
    "\n",
    "# Callback settings\n",
    "EARLY_STOPPING_PATIENCE = 8\n",
    "CHECKPOINT_PATH = Path('../models/denoising_ae_latent128_best.keras')\n",
    "\n",
    "# GPU configuration\n",
    "GPU_ID = 1  # Which GPU to use (0-indexed). Set to None to use all available GPUs.\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure GPU\n",
    "GPU_ID = 0  # Which GPU to use (0-indexed). Set to None to use all available GPUs.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        if GPU_ID is not None:\n",
    "\n",
    "            # Use specific GPU\n",
    "            tf.config.set_visible_devices(gpus[GPU_ID], 'GPU')\n",
    "            tf.config.experimental.set_memory_growth(gpus[GPU_ID], True)\n",
    "            print(f'Using GPU {GPU_ID}: {gpus[GPU_ID].name}')\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Use all GPUs with memory growth\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "            print(f'Using {len(gpus)} GPU(s): {[gpu.name for gpu in gpus]}')\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU available, using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7561a",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0caa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO dataset (cached subset)\n",
    "# First run: Downloads full COCO (~95GB) and saves 10% subset to ../data/\n",
    "# Subsequent runs: Loads quickly from cached subset file\n",
    "(x_train, y_train), (x_test, y_test) = load_coco_cached(subset_percent=10, normalize=True)\n",
    "\n",
    "\n",
    "print(f'Training set: {x_train.shape}')\n",
    "print(f'Test set: {x_test.shape}')\n",
    "print(f'Value range: [{x_train.min():.2f}, {x_train.max():.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b1977",
   "metadata": {},
   "source": [
    "## Visualize Different Noise Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image\n",
    "sample_idx = 15\n",
    "sample_image = x_train[sample_idx:sample_idx+1]\n",
    "\n",
    "# Create noisy versions\n",
    "gaussian_noisy = add_gaussian_noise(sample_image, noise_factor=0.1)\n",
    "salt_pepper_noisy = add_salt_pepper_noise(sample_image, amount=0.1)\n",
    "speckle_noisy = add_speckle_noise(sample_image, noise_factor=0.1)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 4))\n",
    "\n",
    "axes[0].imshow(sample_image[0])\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(gaussian_noisy[0])\n",
    "axes[1].set_title('Gaussian Noise')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(salt_pepper_noisy[0])\n",
    "axes[2].set_title('Salt & Pepper Noise')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(speckle_noisy[0])\n",
    "axes[3].set_title('Speckle Noise')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e85838",
   "metadata": {},
   "source": [
    "## Create Training Data with Noise\n",
    "\n",
    "\n",
    "For this example, we'll focus on Gaussian noise (both for training **and** quantitative evaluation). We'll still visualize other noise types later to highlight that the model specializes in the corruption it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy training and test sets using the same Gaussian factor used during training\n",
    "noise_factor = NOISE_FACTOR\n",
    "\n",
    "\n",
    "x_train_noisy = add_gaussian_noise(x_train, noise_factor=noise_factor)\n",
    "x_test_noisy = add_gaussian_noise(x_test, noise_factor=noise_factor)\n",
    "\n",
    "\n",
    "print(f'Created noisy datasets with Gaussian noise factor: {noise_factor}')\n",
    "print(f'Noisy training set: {x_train_noisy.shape}')\n",
    "print(f'Noisy test set: {x_test_noisy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ed709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clean vs noisy samples\n",
    "n_samples = 8\n",
    "indices = np.random.choice(len(x_train), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(20, 5))\n",
    "fig.suptitle('Clean Images (top) vs Noisy Images (bottom)', fontsize=16, y=1.02)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    axes[0, i].imshow(x_train[idx])\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(x_train_noisy[idx])\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ed09c",
   "metadata": {},
   "source": [
    "## Build Denoising Autoencoder\n",
    "\n",
    "The architecture is similar to a compression autoencoder, but:\n",
    "- **Input**: Noisy images\n",
    "- **Output**: Clean images\n",
    "- The bottleneck forces the network to learn noise-resistant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_denoising_autoencoder(input_shape=(64, 64, 3), latent_dim=128):\n",
    "    '''\n",
    "    Build a denoising autoencoder.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        latent_dim: Dimension of latent bottleneck\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    '''\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(encoder_input)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 32x32\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 16x16\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 8x8\n",
    "    \n",
    "    x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 4x4\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(latent_dim, activation='relu', name='latent')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = layers.Dense(4 * 4 * 512, activation='relu')(latent)\n",
    "    x = layers.Reshape((4, 4, 512))(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(512, 3, activation='relu', strides=2, padding='same')(x)  # 8x8\n",
    "    x = layers.Conv2DTranspose(256, 3, activation='relu', strides=2, padding='same')(x)  # 16x16\n",
    "    x = layers.Conv2DTranspose(128, 3, activation='relu', strides=2, padding='same')(x)  # 32x32\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)   # 64x64\n",
    "    \n",
    "    decoder_output = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # Build model\n",
    "    autoencoder = keras.Model(encoder_input, decoder_output, name='denoising_autoencoder')\n",
    "    \n",
    "    # Compile\n",
    "    autoencoder.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ffb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_denoising_autoencoder(latent_dim=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765f8ac",
   "metadata": {},
   "source": [
    "## Train the Denoising Autoencoder\n",
    "\n",
    "Key insight: We train on **noisy inputs** but optimize to match **clean outputs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Input: noisy images, Target: clean images\n",
    "history = model.fit(\n",
    "    x_train_noisy,  # Noisy input\n",
    "    x_train,        # Clean target\n",
    "    validation_data=(x_test_noisy, x_test),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55159a",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb963aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Loss\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# MAE\n",
    "axes[1].set_title('Mean Absolute Error')\n",
    "axes[1].plot(history.history['mae'], label='Train MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Val MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfaafe4",
   "metadata": {},
   "source": [
    "## Evaluate Denoising Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise test images\n",
    "x_test_denoised = model.predict(x_test_noisy, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_noisy = np.mean((x_test - x_test_noisy) ** 2)\n",
    "mse_denoised = np.mean((x_test - x_test_denoised) ** 2)\n",
    "\n",
    "print('Performance Metrics:')\n",
    "print('=' * 50)\n",
    "print(f'\\nNoisy Images vs Clean:')\n",
    "print(f'  MSE:  {mse_noisy:.6f}')\n",
    "\n",
    "print(f'\\nDenoised Images vs Clean:')\n",
    "print(f'  MSE:  {mse_denoised:.6f}')\n",
    "\n",
    "print(f'\\nImprovement:')\n",
    "print(f'  MSE:  {(mse_noisy - mse_denoised) / mse_noisy * 100:.1f}% reduction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02984863",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e81d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize denoising results\n",
    "n_samples = 8\n",
    "indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(20, 7.5))\n",
    "fig.suptitle('Denoising Results: Original (top) vs Noisy (middle) vs Denoised (bottom)', \n",
    "             fontsize=16, y=0.995)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Original clean image\n",
    "    axes[0, i].imshow(x_test[idx])\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Original', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Noisy image\n",
    "    axes[1, i].imshow(x_test_noisy[idx])\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Noisy', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Denoised image\n",
    "    axes[2, i].imshow(x_test_denoised[idx])\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('Denoised', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Add MSE metric for each image\n",
    "    mse_val = np.mean((x_test[idx:idx+1] - x_test_denoised[idx:idx+1]) ** 2)\n",
    "    axes[2, i].set_title(f'MSE: {mse_val:.4f}', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb328b68",
   "metadata": {},
   "source": [
    "## How the model handles unseen noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare quantitative performance on trained vs unseen noise types\n",
    "comparison_configs = [\n",
    "    ('Gaussian (trained)', lambda imgs: add_gaussian_noise(imgs, noise_factor=NOISE_FACTOR)),\n",
    "    ('Salt & Pepper', lambda imgs: add_salt_pepper_noise(imgs, amount=min(0.5, NOISE_FACTOR / 2))),\n",
    "    ('Speckle', lambda imgs: add_speckle_noise(imgs, noise_factor=NOISE_FACTOR))\n",
    "]\n",
    "\n",
    "\n",
    "generalization_results = []\n",
    "\n",
    "\n",
    "for label, noise_fn in comparison_configs:\n",
    "    noisy_batch = noise_fn(x_test)\n",
    "    denoised_batch = model.predict(noisy_batch, verbose=0)\n",
    "    mse_noisy_val = np.mean((x_test - noisy_batch) ** 2)\n",
    "    mse_denoised_val = np.mean((x_test - denoised_batch) ** 2)\n",
    "    improvement_pct = (mse_noisy_val - mse_denoised_val) / mse_noisy_val * 100\n",
    "    generalization_results.append({\n",
    "        'noise_type': label,\n",
    "        'mse_noisy': mse_noisy_val,\n",
    "        'mse_denoised': mse_denoised_val,\n",
    "        'improvement_pct': improvement_pct\n",
    "    })\n",
    "\n",
    "\n",
    "print('\\nModel performance across noise types (trained on Gaussian only):')\n",
    "print('=' * 90)\n",
    "print(f'{\"Noise Type\":<20} | {\"MSE Noisy\":>12} | {\"MSE Denoised\":>14} | {\"Improvement\":>12}')\n",
    "print('-' * 90)\n",
    "for r in generalization_results:\n",
    "    print(\n",
    "        f\"{r['noise_type']:<20} | \"\n",
    "        f\"{r['mse_noisy']:>12.6f} | \"\n",
    "        f\"{r['mse_denoised']:>14.6f} | \"\n",
    "        f\"{r['improvement_pct']:>10.1f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c04cc3",
   "metadata": {},
   "source": [
    "## Experiment: Different Noise Levels\n",
    "\n",
    "Let's test how the model performs on different noise levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c848c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on different noise levels\n",
    "noise_levels = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "results = []\n",
    "\n",
    "for noise_factor in noise_levels:\n",
    "\n",
    "    # Create noisy images\n",
    "    x_test_noisy_temp = add_gaussian_noise(x_test, noise_factor=noise_factor)\n",
    "    \n",
    "    # Denoise\n",
    "    x_test_denoised_temp = model.predict(x_test_noisy_temp, verbose=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_before = np.mean((x_test - x_test_noisy_temp) ** 2)\n",
    "    mse_after = np.mean((x_test - x_test_denoised_temp) ** 2)\n",
    "    improvement = (mse_before - mse_after) / mse_before * 100\n",
    "    \n",
    "    results.append({\n",
    "        'noise_factor': noise_factor,\n",
    "        'mse_before': mse_before,\n",
    "        'mse_after': mse_after,\n",
    "        'improvement_pct': improvement\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "print('\\nPerformance across different noise levels:')\n",
    "print('=' * 70)\n",
    "print(f'{\"Noise\":>8} | {\"MSE Before\":>12} | {\"MSE After\":>12} | {\"Improvement\":>12}')\n",
    "print('-' * 70)\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['noise_factor']:>8.2f} | \"\n",
    "        f\"{r['mse_before']:>12.6f} | \"\n",
    "        f\"{r['mse_after']:>12.6f} | \"\n",
    "        f\"{r['improvement_pct']:>11.1f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance across noise levels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "noise_factors = [r['noise_factor'] for r in results]\n",
    "mse_before_vals = [r['mse_before'] for r in results]\n",
    "mse_after_vals = [r['mse_after'] for r in results]\n",
    "improvement_vals = [r['improvement_pct'] for r in results]\n",
    "\n",
    "# MSE comparison\n",
    "axes[0].plot(\n",
    "    noise_factors, mse_before_vals,\n",
    "    'o-', label='Before Denoising', linewidth=2, markersize=8\n",
    ")\n",
    "axes[0].plot(\n",
    "    noise_factors, mse_after_vals,\n",
    "    's-', label='After Denoising', linewidth=2, markersize=8\n",
    ")\n",
    "axes[0].set_xlabel('Noise Factor', fontsize=12)\n",
    "axes[0].set_ylabel('MSE', fontsize=12)\n",
    "axes[0].set_title('MSE vs Noise Level', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Relative improvement\n",
    "axes[1].plot(\n",
    "    noise_factors, improvement_vals,\n",
    "    'd-', color='tab:green', linewidth=2, markersize=8\n",
    ")\n",
    "axes[1].set_xlabel('Noise Factor', fontsize=12)\n",
    "axes[1].set_ylabel('MSE Improvement (%)', fontsize=12)\n",
    "axes[1].set_title('Relative Improvement vs Noise', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51af0be",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the denoising model\n",
    "model_path = '../models/denoising_ae_latent128.keras'\n",
    "model.save(model_path)\n",
    "print(f'Model saved to: {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
