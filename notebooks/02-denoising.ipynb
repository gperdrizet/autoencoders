{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d68789a",
   "metadata": {},
   "source": [
    "# Denoising autoencoder\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0db006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Local imports\n",
    "from src.data_utils import load_coco_cached\n",
    "from src.visualization import plot_image_grid\n",
    "from src.metrics import calculate_psnr, calculate_ssim\n",
    "from src.noise import add_gaussian_noise, add_salt_pepper_noise, add_speckle_noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95daa795",
   "metadata": {},
   "source": [
    "### 1.2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f59d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 1: /physical_device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "TRAIN_MODEL = True  # Set to False to download pre-trained model from HuggingFace\n",
    "\n",
    "# Training hyperparameters\n",
    "LATENT_DIM = 128\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Noise parameters\n",
    "NOISE_FACTOR = 0.25\n",
    "\n",
    "# GPU configuration\n",
    "GPU_ID = 1  # Which GPU to use (0-indexed). Set to None to use all available GPUs.\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure GPU\n",
    "GPU_ID = 0  # Which GPU to use (0-indexed). Set to None to use all available GPUs.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        if GPU_ID is not None:\n",
    "\n",
    "            # Use specific GPU\n",
    "            tf.config.set_visible_devices(gpus[GPU_ID], 'GPU')\n",
    "            tf.config.experimental.set_memory_growth(gpus[GPU_ID], True)\n",
    "            print(f'Using GPU {GPU_ID}: {gpus[GPU_ID].name}')\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Use all GPUs with memory growth\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "            print(f'Using {len(gpus)} GPU(s): {[gpu.name for gpu in gpus]}')\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU available, using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7561a",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "We'll use a 10% subset of the COCO 2017 dataset (~11,800 diverse images across 80 categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0caa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (11829, 64, 64, 3)\n",
      "Test set: (1000, 64, 64, 3)\n",
      "Value range: [0.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "# Load COCO dataset (10% subset with caching)\n",
    "# First run: Downloads full COCO (~95GB) and saves 10% subset to ../data/\n",
    "# Subsequent runs: Loads quickly from cached subset file\n",
    "(x_train, y_train), (x_test, y_test) = load_coco_cached(subset_percent=10, normalize=True)\n",
    "\n",
    "print(f'Training set: {x_train.shape}')\n",
    "print(f'Test set: {x_test.shape}')\n",
    "print(f'Value range: [{x_train.min():.2f}, {x_train.max():.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b1977",
   "metadata": {},
   "source": [
    "## Visualize Different Noise Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1353761d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create noisy versions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m gaussian_noisy \u001b[38;5;241m=\u001b[39m add_gaussian_noise(sample_image, noise_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m salt_pepper_noisy \u001b[38;5;241m=\u001b[39m \u001b[43madd_salt_pepper_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m speckle_noisy \u001b[38;5;241m=\u001b[39m add_speckle_noise(sample_image, noise_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Plot comparison\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36madd_salt_pepper_noise\u001b[0;34m(images, amount)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Salt (white pixels)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m num_salt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(amount \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m coords \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_salt) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m images\u001b[38;5;241m.\u001b[39mshape]\n\u001b[1;32m     32\u001b[0m noisy_images[coords[\u001b[38;5;241m0\u001b[39m], coords[\u001b[38;5;241m1\u001b[39m], coords[\u001b[38;5;241m2\u001b[39m], coords[\u001b[38;5;241m3\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Pepper (black pixels)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Salt (white pixels)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m num_salt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(amount \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m coords \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_salt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m images\u001b[38;5;241m.\u001b[39mshape]\n\u001b[1;32m     32\u001b[0m noisy_images[coords[\u001b[38;5;241m0\u001b[39m], coords[\u001b[38;5;241m1\u001b[39m], coords[\u001b[38;5;241m2\u001b[39m], coords[\u001b[38;5;241m3\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Pepper (black pixels)\u001b[39;00m\n",
      "File \u001b[0;32mmtrand.pyx:765\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "# Select a sample image\n",
    "sample_idx = 42\n",
    "sample_image = x_train[sample_idx:sample_idx+1]\n",
    "\n",
    "# Create noisy versions\n",
    "gaussian_noisy = add_gaussian_noise(sample_image, noise_factor=0.3)\n",
    "salt_pepper_noisy = add_salt_pepper_noise(sample_image, amount=0.05)\n",
    "speckle_noisy = add_speckle_noise(sample_image, noise_factor=0.2)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(sample_image[0])\n",
    "axes[0].set_title('Original', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(gaussian_noisy[0])\n",
    "axes[1].set_title('Gaussian Noise', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(salt_pepper_noisy[0])\n",
    "axes[2].set_title('Salt & Pepper Noise', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(speckle_noisy[0])\n",
    "axes[3].set_title('Speckle Noise', fontsize=14)\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e85838",
   "metadata": {},
   "source": [
    "## Create Training Data with Noise\n",
    "\n",
    "For this example, we'll focus on Gaussian noise as it's the most common type in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy training and test sets\n",
    "noise_factor = 0.25\n",
    "\n",
    "x_train_noisy = add_gaussian_noise(x_train, noise_factor=noise_factor)\n",
    "x_test_noisy = add_gaussian_noise(x_test, noise_factor=noise_factor)\n",
    "\n",
    "print(f'Created noisy datasets with noise factor: {noise_factor}')\n",
    "print(f'Noisy training set: {x_train_noisy.shape}')\n",
    "print(f'Noisy test set: {x_test_noisy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ed709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clean vs noisy samples\n",
    "n_samples = 8\n",
    "indices = np.random.choice(len(x_train), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(20, 5))\n",
    "fig.suptitle('Clean Images (top) vs Noisy Images (bottom)', fontsize=16, y=1.02)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    axes[0, i].imshow(x_train[idx])\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(x_train_noisy[idx])\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ed09c",
   "metadata": {},
   "source": [
    "## Build Denoising Autoencoder\n",
    "\n",
    "The architecture is similar to a compression autoencoder, but:\n",
    "- **Input**: Noisy images\n",
    "- **Output**: Clean images\n",
    "- The bottleneck forces the network to learn noise-resistant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_denoising_autoencoder(input_shape=(64, 64, 3), latent_dim=128):\n",
    "    '''\n",
    "    Build a denoising autoencoder.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        latent_dim: Dimension of latent bottleneck\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    '''\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(encoder_input)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 32x32\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 16x16\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 8x8\n",
    "    \n",
    "    x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 4x4\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(latent_dim, activation='relu', name='latent')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = layers.Dense(4 * 4 * 512, activation='relu')(latent)\n",
    "    x = layers.Reshape((4, 4, 512))(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(512, 3, activation='relu', strides=2, padding='same')(x)  # 8x8\n",
    "    x = layers.Conv2DTranspose(256, 3, activation='relu', strides=2, padding='same')(x)  # 16x16\n",
    "    x = layers.Conv2DTranspose(128, 3, activation='relu', strides=2, padding='same')(x)  # 32x32\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)   # 64x64\n",
    "    \n",
    "    decoder_output = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # Build model\n",
    "    autoencoder = keras.Model(encoder_input, decoder_output, name='denoising_autoencoder')\n",
    "    \n",
    "    # Compile\n",
    "    autoencoder.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ffb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_denoising_autoencoder(latent_dim=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765f8ac",
   "metadata": {},
   "source": [
    "## Train the Denoising Autoencoder\n",
    "\n",
    "Key insight: We train on **noisy inputs** but optimize to match **clean outputs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Input: noisy images, Target: clean images\n",
    "history = model.fit(\n",
    "    x_train_noisy,  # Noisy input\n",
    "    x_train,        # Clean target\n",
    "    validation_data=(x_test_noisy, x_test),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55159a",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb963aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('MAE', fontsize=12)\n",
    "axes[1].set_title('Mean Absolute Error', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfaafe4",
   "metadata": {},
   "source": [
    "## Evaluate Denoising Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise test images\n",
    "x_test_denoised = model.predict(x_test_noisy, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_noisy = np.mean((x_test - x_test_noisy) ** 2)\n",
    "mse_denoised = np.mean((x_test - x_test_denoised) ** 2)\n",
    "\n",
    "psnr_noisy = calculate_psnr(x_test, x_test_noisy)\n",
    "psnr_denoised = calculate_psnr(x_test, x_test_denoised)\n",
    "\n",
    "ssim_noisy = calculate_ssim(x_test, x_test_noisy)\n",
    "ssim_denoised = calculate_ssim(x_test, x_test_denoised)\n",
    "\n",
    "print('Performance Metrics:')\n",
    "print('=' * 50)\n",
    "print(f'\\nNoisy Images vs Clean:')\n",
    "print(f'  MSE:  {mse_noisy:.6f}')\n",
    "print(f'  PSNR: {psnr_noisy:.2f} dB')\n",
    "print(f'  SSIM: {ssim_noisy:.4f}')\n",
    "\n",
    "print(f'\\nDenoised Images vs Clean:')\n",
    "print(f'  MSE:  {mse_denoised:.6f}')\n",
    "print(f'  PSNR: {psnr_denoised:.2f} dB')\n",
    "print(f'  SSIM: {ssim_denoised:.4f}')\n",
    "\n",
    "print(f'\\nImprovement:')\n",
    "print(f'  MSE:  {(mse_noisy - mse_denoised) / mse_noisy * 100:.1f}% reduction')\n",
    "print(f'  PSNR: {psnr_denoised - psnr_noisy:.2f} dB increase')\n",
    "print(f'  SSIM: {(ssim_denoised - ssim_noisy) / (1 - ssim_noisy) * 100:.1f}% closer to perfect')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02984863",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e81d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize denoising results\n",
    "n_samples = 8\n",
    "indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(20, 7.5))\n",
    "fig.suptitle('Denoising Results: Original (top) vs Noisy (middle) vs Denoised (bottom)', \n",
    "             fontsize=16, y=0.995)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Original clean image\n",
    "    axes[0, i].imshow(x_test[idx])\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Original', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Noisy image\n",
    "    axes[1, i].imshow(x_test_noisy[idx])\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Noisy', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Denoised image\n",
    "    axes[2, i].imshow(x_test_denoised[idx])\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('Denoised', fontsize=12, rotation=0, labelpad=40, va='center')\n",
    "    \n",
    "    # Add metrics for each image\n",
    "    psnr_val = calculate_psnr(x_test[idx:idx+1], x_test_denoised[idx:idx+1])\n",
    "    ssim_val = calculate_ssim(x_test[idx:idx+1], x_test_denoised[idx:idx+1])\n",
    "    axes[2, i].set_title(f'PSNR: {psnr_val:.1f}dB\\nSSIM: {ssim_val:.3f}', \n",
    "                         fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c04cc3",
   "metadata": {},
   "source": [
    "## Experiment: Different Noise Levels\n",
    "\n",
    "Let's test how the model performs on different noise levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c848c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on different noise levels\n",
    "noise_levels = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "results = []\n",
    "\n",
    "for noise_factor in noise_levels:\n",
    "    # Create noisy images\n",
    "    x_test_noisy_temp = add_gaussian_noise(x_test, noise_factor=noise_factor)\n",
    "    \n",
    "    # Denoise\n",
    "    x_test_denoised_temp = model.predict(x_test_noisy_temp, verbose=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    psnr_before = calculate_psnr(x_test, x_test_noisy_temp)\n",
    "    psnr_after = calculate_psnr(x_test, x_test_denoised_temp)\n",
    "    ssim_before = calculate_ssim(x_test, x_test_noisy_temp)\n",
    "    ssim_after = calculate_ssim(x_test, x_test_denoised_temp)\n",
    "    \n",
    "    results.append({\n",
    "        'noise_factor': noise_factor,\n",
    "        'psnr_before': psnr_before,\n",
    "        'psnr_after': psnr_after,\n",
    "        'ssim_before': ssim_before,\n",
    "        'ssim_after': ssim_after\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "print('\\nPerformance across different noise levels:')\n",
    "print('=' * 80)\n",
    "print(f'{\"Noise\":>8} | {\"PSNR Before\":>12} | {\"PSNR After\":>12} | {\"SSIM Before\":>12} | {\"SSIM After\":>12}')\n",
    "print('-' * 80)\n",
    "for r in results:\n",
    "    print(f'{r[\"noise_factor\"]:>8.2f} | {r[\"psnr_before\"]:>12.2f} | {r[\"psnr_after\"]:>12.2f} | '\n",
    "          f'{r[\"ssim_before\"]:>12.4f} | {r[\"ssim_after\"]:>12.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance across noise levels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "noise_factors = [r['noise_factor'] for r in results]\n",
    "\n",
    "# PSNR\n",
    "axes[0].plot(noise_factors, [r['psnr_before'] for r in results], \n",
    "             'o-', label='Before Denoising', linewidth=2, markersize=8)\n",
    "axes[0].plot(noise_factors, [r['psnr_after'] for r in results], \n",
    "             's-', label='After Denoising', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Noise Factor', fontsize=12)\n",
    "axes[0].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "axes[0].set_title('PSNR vs Noise Level', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM\n",
    "axes[1].plot(noise_factors, [r['ssim_before'] for r in results], \n",
    "             'o-', label='Before Denoising', linewidth=2, markersize=8)\n",
    "axes[1].plot(noise_factors, [r['ssim_after'] for r in results], \n",
    "             's-', label='After Denoising', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Noise Factor', fontsize=12)\n",
    "axes[1].set_ylabel('SSIM', fontsize=12)\n",
    "axes[1].set_title('SSIM vs Noise Level', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51af0be",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the denoising model\n",
    "model_path = '../models/denoising_ae_latent128.keras'\n",
    "model.save(model_path)\n",
    "print(f'Model saved to: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124b6cc",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Training Strategy**: Denoising autoencoders are trained with noisy inputs and clean targets\n",
    "\n",
    "2. **Robust Features**: The bottleneck forces the network to learn features that are resistant to noise\n",
    "\n",
    "3. **Generalization**: The model trained on one noise level can still denoise images with different noise levels, though performance degrades with very high noise\n",
    "\n",
    "4. **Applications**: Beyond image denoising, this approach is useful for:\n",
    "   - Pretraining encoders for other tasks\n",
    "   - Data augmentation\n",
    "   - Regularization technique\n",
    "\n",
    "5. **Limitations**: \n",
    "   - Works best when test noise is similar to training noise\n",
    "   - May blur fine details while removing noise\n",
    "   - Performance depends on bottleneck size and architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
